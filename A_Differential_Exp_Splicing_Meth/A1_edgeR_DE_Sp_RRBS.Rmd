---
title: "edgeR_DE_Sp_RRBS_ATAC"
author: "Sam Bogan"
date: "5/14/2021"
output: rmarkdown::github_document
---
This is an R markdown document detailing edgeR analysis of differential expression for the Sp_RRBS_ATAC repo, a documentation of analyses by Sam Bogan, Marie Strader, and Gretchen Hofmann that aimed to understand the gene regulatory effects of DNA methylation during transgenerational plasticity in the purple sea urchin *Strongylocentrotus purpuratus* and how these effects are regulated by other epigenomic and genomic states.

The code below reads in and filters an RNAseq count matrix, performs a PCA of each sample, and then fits a multifactorial glm from which pariwise contrasts are made to estimate differential expression between treatment groups. Developmental treatment: larval S. purpuratus reared in experimental upwelling or non-upwelling conditions. Maternal treatment:  larval S. purpuratus spawned from mothers exposed to experimental upwelling or non-upwelling conditions.

This markdown finishes by outputing two dataframes containing logCPM, logFC, and p-values for differential expression produced by contrasts between developmental and maternal treatments.

Prior to this analysis, reads were mapped to the Spur_3.1.42 assembly and annotation using HiSat2 and counted using featureCounts in the subread package as detailed in Strader et al. 2020: https://www.frontiersin.org/articles/10.3389/fmars.2020.00205/full. Relevant scripts for alignment and read counting can be found at: https://github.com/mariestrader/S.purp_RRBS_RNAseq_2019.

```{r setup, include=FALSE}

knitr::opts_knit$set( root.dir = '~/Documents/GitHub/Sp_RRBS_ATAC/A_Differential_Exp_Splicing_Meth/' )

```

#Read in, filter, and multiQC data

```{r}

# Load required packages
library( edgeR )
library( tidyverse )
library( pheatmap )
library( ape )
library( vegan )

# Read in csv of read counts per gene
gene_counts <- read.csv( "Input_data/gene_read_counts.csv" )

# Remove duplicated transcripts
n_occur_gc <- data.frame( table(gene_counts$Geneid ) )
n_occur_gc <- n_occur_gc[ n_occur_gc$Freq > 1, ]
n_occur_gc <- n_occur_gc$Var1

gene_counts <- gene_counts[ ! gene_counts$Geneid %in% n_occur_gc, ]

#Make gene id matrix rowname
row.names( gene_counts ) <- gene_counts$Geneid

gene_counts <- subset( gene_counts, 
                       select = -c( Geneid, 
                                    Chr, 
                                    Start, 
                                    End, 
                                    Strand, 
                                    Length ) )

```

```{r}

# Replace sample IDs with simple names
colnames( gene_counts ) <- c( "NN1","NN2","NN3","NU1","NU2","NU3",
                     "UN1","UN2","UN3","UU1","UU2","UU3" )

# Create treatment group df
Mat = c( "N","N","N","N","N","N",
         "U","U","U","U","U","U" )

Dev = c( "N","N","N","U","U","U",
         "N","N","N","U","U","U" )

targets_gc <- data.frame( Mat = c( "N","N","N","N","N","N",
                                   "U","U","U","U","U","U" ), 
                          Dev = c( "N","N","N","U","U","U",
                                   "N","N","N","U","U","U" ) )

targets_gc$grouping <- paste( targets_gc$Mat, 
                             targets_gc$Dev,
                             sep="_" )

# Round counts (if necessary() for use in edgeR
data_input_gc <- round( gene_counts )

```

```{r}

# Make a DGEList
DGEList <- DGEList( counts = data_input_gc, 
                    group = targets_gc$grouping, 
                    remove.zeros = T )

# Let's remove genes with less then 0.5 cpm (this is ~10 counts in the count file) in no fewer then 9 samples
DGEList_keep <- rowSums( cpm( DGEList ) > 0.5 ) >= 9

# How many genes are removed by read count filter?
table( DGEList_keep )

# Filter and set keep.lib.sizes = F to have R recalculate library sizes after filtering
DGEList <- DGEList[ DGEList_keep, 
                    keep.lib.sizes = FALSE ]

# Create library size normalization factors
DGEList <- calcNormFactors( DGEList )


# CPM conversion and log^2 transformation of read counts
DGEList_log <- cpm( DGEList,
                    log = TRUE, 
                    prior.count = 2 )

# MDS of normalized gene read counts
MDS <- plotMDS( DGEList_log )

# Print MDS plot
MDS

# Run pcoa on gene read counts
pcoa_gc <- pcoa( vegdist( t( DGEList_log <- cpm ( DGEList, 
                                                  log = TRUE, 
                                                  prior.count = 2 ) ), 
                          method = "euclidean" ) / 1000 )

# Print sample scores across vectors
head( pcoa_gc$vectors )

# Export DGEList_keep
save( DGEList_keep,
      file = "Output_data/DGEList_keep.Rdata" )
```

```{r}

# Create model design that includes maternal and developmental effects and set intercept to 0
design_multi_gc <- model.matrix( ~0 + Mat + Dev )

# Add column names to model matrix
colnames( design_multi_gc ) <- c( "MatN", "MatU", "DevU" ) 

# Filter and normalize count matrix input
gene_counts_matrix <- as.matrix(gene_counts)

DGEList <- DGEList( counts = gene_counts_matrix, 
                    group = targets_gc$grouping, 
                    remove.zeros = T )

DGEList <- DGEList[ DGEList_keep, 
                    keep.lib.sizes = FALSE ]

DGEList <- calcNormFactors( DGEList )

# Estmate mean dispersal for use in plotting common dispersal against tagwise dispersal
DGEList <- estimateGLMCommonDisp( DGEList, 
                                  design_multi_gc )

# Estmate robust, Bayesian dispersal per gene for estimating regression parameters for glmQL and differential expression
DGEList <- estimateGLMRobustDisp( DGEList, 
                                  design_multi_gc ) 

# Plot tagwise dispersal and impose w/mean dispersal and trendline
plotBCV( DGEList ) 

# Fit a robust, multifactorial quasi-likelihood glm to normalized read counts
fit_gc <- glmQLFit( DGEList, 
                    design_multi_gc, 
                    robust = TRUE )

# Plot shrinkage of Bayesian quasi-likelihood dispersion to visualize stastical power of DE analysis
plotQLDisp( fit_gc ) # High shrinkage / high statistical power across DE tests

```

#Perform differential expression analyses

```{r}

## Pairwise comparison of maternal differential expression

# Design contrast between samples based on maternal effect
con_Maternal <- makeContrasts( con_Maternal_cons = MatU - MatN,
                               levels = design_multi_gc )

# Apply quasi-likelihood F test to incorporate Bayesian tagwise dispersion estimates as parameter for DEG analysis
maternal_QLFT <- glmQLFTest( fit_gc, 
                           contrast = con_Maternal )

# Plot maternal logFC across logCPM (fdr < 0.05)
plotMD( maternal_QLFT )

# How many significant DEGs? 2405
summary( decideTestsDGE( maternal_QLFT, 
                         adjust.method = "fdr",
                         p.value = 0.05 ) )

# Filter for significance and logFC cutoff (doubling of fold change or logFC of 1)
maternal_QLFT_cutoff <- topTags( maternal_QLFT, 
                                   n = ( 1025 + 1380 ), 
                                   adjust.method = "fdr",
                                   p.value = 0.05 )

# Create df of logFC and sign cutoff DEGs
maternal_QLFT_cutoff_df <- data.frame( maternal_QLFT_cutoff$table )
maternal_QLFT_fc_cutoff_df <- maternal_QLFT_cutoff_df[ !( abs( maternal_QLFT_cutoff_df$logFC ) < 1 ), ]

# Count total DEGs with logFC cutoff
nrow( maternal_QLFT_cutoff_df ) # Without logFC cutoff = 2405 DEGs
nrow( maternal_QLFT_fc_cutoff_df ) # With logFC cutoff = 245 DEGs

```

```{r}

## Pairwise comparison of developmental differential expression

# Pairwise comparison of developmental differential expression
con_Dev <- makeContrasts( con_Dev_cons = DevU, 
                          levels = design_multi_gc)

# Apply quasi-likelihood F test to incorporate Bayesian tagwise dispersion estimates as parameter for DEG analysis
dev_QLFT <- glmQLFTest( fit_gc, 
                   contrast = con_Dev )

# Plot maternal logFC across logCPM (fdr < 0.05)
plotMD( dev_QLFT )

# How many significant DEGs? 4722
summary( decideTestsDGE( dev_QLFT, 
                         adjust.method = "fdr",
                         p.value = 0.05 ) )

# Filter for significance and logFC cutoff
dev_QLFT_cutoff <- topTags( dev_QLFT, 
                                n = ( 2459 + 2263 ), 
                                adjust.method = "fdr",
                                p.value = 0.05 )

# Create df of logFC and sig cutoff DEGs (doubling of fold change or logFC of 1)
dev_QLFT_cutoff_df <- data.frame( dev_QLFT_cutoff$table )
dev_QLFT_fc_cutoff_df <- dev_QLFT_cutoff_df[ !( abs( dev_QLFT_cutoff_df$logFC ) < 1 ), ]

# Count total DEGs with logFC cutoff
nrow( dev_QLFT_cutoff_df ) # Without logFC cutoff = 4722 DEGs
nrow( dev_QLFT_fc_cutoff_df ) # With logFC cutoff = 309 DEGs

```

#Export DE data from maternal and developmental contrasts

``` {r}

# Export maternal and developmental glm table as .csv files
write.csv( maternal_QLFT$table, 
           "Output_data/mat_edgeR_GE_table_filt.csv")

write.csv( dev_QLFT$table, 
          "Output_data/dev_edgeR_GE_table_filt.csv" )

```